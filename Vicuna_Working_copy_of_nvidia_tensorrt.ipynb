{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swetha097/FAMBench/blob/main/Vicuna_Working_copy_of_nvidia_tensorrt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CVSWc7kVLjD"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/llm/nvidia_tensorrt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which python\n",
        "!nvidia-smi\n",
        "!which pip\n",
        "!python --version\n",
        "!apt-get update && apt-get -y install python3.10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htHXTyVrVaL8",
        "outputId": "9f66d863-c6a7-4f5b-a207-47ed313bd2d6",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n",
            "Thu Jan 30 04:40:38 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "/usr/local/bin/pip\n",
            "Python 3.11.11\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [62.9 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,304 kB]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,229 kB]\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,632 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,604 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,904 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,606 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,521 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,647 kB]\n",
            "Fetched 24.9 MB in 5s (5,444 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "python3.10 is already the newest version (3.10.12-1~22.04.8).\n",
            "python3.10 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 22 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "!python3 --version\n",
        "!which python\n",
        "!which python3\n",
        "!which python3.10"
      ],
      "metadata": {
        "id": "Xp4v_Oj9d45k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ccd3a5bc-134e-41a6-881e-898b2c5d7924"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.11\n",
            "Python 3.11.11\n",
            "/usr/local/bin/python\n",
            "/usr/bin/python3\n",
            "/usr/bin/python3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -sf /usr/bin/python3.10 /usr/local/bin/python\n",
        "!ln -sf /usr/bin/python3.10 /usr/local/bin/python3\n",
        "!ln -sf /usr/bin/python3.10 /usr/bin/python3\n",
        "!which python\n",
        "!apt install python3-pip openmpi-bin libopenmpi-dev git git-lfs wget"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCDNtFlqWODl",
        "outputId": "af47da25-161f-4892-f8c3-25803fdabff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "libopenmpi-dev is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin is already the newest version (4.1.2-2ubuntu1).\n",
            "openmpi-bin set to manually installed.\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "wget is already the newest version (1.21.2-2ubuntu1.1).\n",
            "git-lfs is already the newest version (3.0.2-1ubuntu0.3).\n",
            "The following additional packages will be installed:\n",
            "  python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 3 newly installed, 0 to remove and 22 not upgraded.\n",
            "Need to get 1,677 kB of archives.\n",
            "After this operation, 8,968 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-setuptools all 59.6.0-1.2ubuntu0.22.04.2 [340 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-wheel all 0.37.1-2ubuntu0.22.04.1 [32.0 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip all 22.0.2+dfsg-1ubuntu0.5 [1,306 kB]\n",
            "Fetched 1,677 kB in 2s (973 kB/s)\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "(Reading database ... 124950 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-setuptools_59.6.0-1.2ubuntu0.22.04.2_all.deb ...\n",
            "Unpacking python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.37.1-2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_22.0.2+dfsg-1ubuntu0.5_all.deb ...\n",
            "Unpacking python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Setting up python3-setuptools (59.6.0-1.2ubuntu0.22.04.2) ...\n",
            "Setting up python3-wheel (0.37.1-2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip (22.0.2+dfsg-1ubuntu0.5) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which pip3\n",
        "!pip --version"
      ],
      "metadata": {
        "id": "mPpBVoA2YS0n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f0ad297-e9a4-4bc1-df1b-39ccc643c94d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/pip3\n",
            "pip 22.0.2 from /usr/lib/python3/dist-packages/pip (python 3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pn2oMm7IlTtP",
        "outputId": "2db0eec8-5c66-4b45-dfde-44f6c419159e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pip 22.0.2 from /usr/lib/python3/dist-packages/pip (python 3.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which python3\n",
        "!which python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D34si03lo8qx",
        "outputId": "c964af1e-5628-4436-dcdc-1ace0c248e81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/bin/python3\n",
            "/usr/local/bin/python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install tensorrt_llm==0.16 --extra-index-url https://pypi.nvidia.com"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRkpOO94WRjM",
        "outputId": "9ab6310e-2f6f-495e-ade3-493eb02835a4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
            "Collecting tensorrt_llm==0.16\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-llm/tensorrt_llm-0.16.0-cp310-cp310-linux_x86_64.whl (1551.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 GB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colored\n",
            "  Downloading colored-2.2.5-py3-none-any.whl (16 kB)\n",
            "Collecting httpx\n",
            "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting psutil\n",
            "  Downloading psutil-6.1.1-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (287 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 KB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting StrEnum\n",
            "  Downloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\n",
            "Collecting mpmath>=1.3.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 KB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml>=11.5.0\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl (26 kB)\n",
            "Collecting click\n",
            "  Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lark\n",
            "  Downloading lark-1.2.2-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 KB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx-graphsurgeon>=0.5.2\n",
            "  Downloading https://pypi.nvidia.com/onnx-graphsurgeon/onnx_graphsurgeon-0.5.5-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m210.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyzmq\n",
            "  Downloading pyzmq-26.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 KB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai==1.54.3\n",
            "  Downloading openai-1.54.3-py3-none-any.whl (389 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 KB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cuda-python\n",
            "  Downloading cuda_python-12.8.0-py3-none-any.whl (11 kB)\n",
            "Collecting build\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from tensorrt_llm==0.16) (0.37.1)\n",
            "Collecting click-option-group\n",
            "  Downloading click_option_group-0.5.6-py3-none-any.whl (12 kB)\n",
            "Collecting diffusers>=0.27.0\n",
            "  Downloading diffusers-0.32.2-py3-none-any.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting polygraphy\n",
            "  Downloading https://pypi.nvidia.com/polygraphy/polygraphy-0.49.14-py2.py3-none-any.whl (353 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.0/353.0 KB\u001b[0m \u001b[31m139.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece>=0.1.99\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt~=10.7.0\n",
            "  Downloading https://pypi.nvidia.com/tensorrt/tensorrt-10.7.0.post1.tar.gz (35 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting accelerate>=0.25.0\n",
            "  Downloading accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.6/336.6 KB\u001b[0m \u001b[31m37.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-modelopt[torch]~=0.21.0\n",
            "  Downloading https://pypi.nvidia.com/nvidia-modelopt/nvidia_modelopt-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m188.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mpi4py\n",
            "  Downloading mpi4py-4.0.1.tar.gz (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.2/466.2 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers<=4.45.1,>=4.38.2\n",
            "  Downloading transformers-4.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py==3.12.1\n",
            "  Downloading h5py-3.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aenum\n",
            "  Downloading aenum-3.1.15-py3-none-any.whl (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorrt_llm==0.16) (59.6.0)\n",
            "Collecting nvidia-nccl-cu12\n",
            "  Downloading https://pypi.nvidia.com/nvidia-nccl-cu12/nvidia_nccl_cu12-2.25.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pulp\n",
            "  Downloading PuLP-2.9.0-py3-none-any.whl (17.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.7/17.7 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum\n",
            "  Downloading optimum-1.23.3-py3-none-any.whl (424 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.1/424.1 KB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting onnx>=1.12.0\n",
            "  Downloading onnx-1.17.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ordered-set\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pillow==10.3.0\n",
            "  Downloading pillow-10.3.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi==0.115.4\n",
            "  Downloading fastapi-0.115.4-py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.7/94.7 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic>=2.9.1\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 KB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch<=2.6.0a0,>=2.5.1\n",
            "  Downloading torch-2.5.1-cp310-cp310-manylinux1_x86_64.whl (906.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-2.2.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.8.0\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sniffio\n",
            "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.54.3->tensorrt_llm==0.16) (1.7.0)\n",
            "Collecting anyio<5,>=3.5.0\n",
            "  Downloading anyio-4.8.0-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.0/96.0 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jiter<1,>=0.4.0\n",
            "  Downloading jiter-0.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.0/345.0 KB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm>4\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 KB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
            "Collecting safetensors>=0.4.3\n",
            "  Downloading safetensors-0.5.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (461 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m462.0/462.0 KB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml\n",
            "  Downloading PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (751 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m751.2/751.2 KB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.21.0\n",
            "  Downloading huggingface_hub-0.28.0-py3-none-any.whl (464 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m464.1/464.1 KB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers>=0.27.0->tensorrt_llm==0.16) (4.6.4)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.7/781.7 KB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 KB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna\n",
            "  Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 KB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi\n",
            "  Downloading certifi-2024.12.14-py3-none-any.whl (164 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.9/164.9 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.*\n",
            "  Downloading httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 KB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.9/422.9 KB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (40.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.6/40.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich\n",
            "  Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 KB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cloudpickle>=1.6.0\n",
            "  Downloading cloudpickle-3.1.1-py3-none-any.whl (20 kB)\n",
            "Collecting torchprofile>=0.0.4\n",
            "  Downloading torchprofile-0.0.4-py3-none-any.whl (7.7 kB)\n",
            "Collecting protobuf>=3.20.2\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic-core==2.27.2\n",
            "  Downloading pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting annotated-types>=0.6.0\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting nvidia-ml-py<13.0.0a0,>=12.0.0\n",
            "  Downloading nvidia_ml_py-12.570.86-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt_cu12==10.7.0.post1\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-cu12/tensorrt_cu12-10.7.0.post1.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorrt_cu12_bindings==10.7.0.post1\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-cu12-bindings/tensorrt_cu12_bindings-10.7.0.post1-cp310-none-manylinux_2_17_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorrt_cu12_libs==10.7.0.post1\n",
            "  Downloading https://pypi.nvidia.com/tensorrt-cu12-libs/tensorrt_cu12_libs-10.7.0.post1-py2.py3-none-manylinux_2_17_x86_64.whl (2070.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 GB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.8.57-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 KB\u001b[0m \u001b[31m214.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12\n",
            "  Downloading https://pypi.nvidia.com/nvidia-nccl-cu12/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127\n",
            "  Downloading https://pypi.nvidia.com/nvidia-nvtx-cu12/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 KB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m97.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cusolver-cu12/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m64.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cuda-cupti-cu12/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m176.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.6/134.6 KB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127\n",
            "  Downloading https://pypi.nvidia.com/nvidia-nvjitlink-cu12/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m173.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.4.127\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cuda-nvrtc-cu12/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m179.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cusparse-cu12/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cufft-cu12/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cublas-cu12/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147\n",
            "  Downloading https://pypi.nvidia.com/nvidia-curand-cu12/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec\n",
            "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/de/86/5486b0188d08aa643e127774a99bac51ffa6cf343e3deb0583956dca5b22/fsspec-2024.12.0-py3-none-any.whl\u001b[0m\u001b[33m\n",
            "\u001b[0m  Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12\n",
            "  Downloading https://pypi.nvidia.com/nvidia-cuda-runtime-cu12/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 KB\u001b[0m \u001b[31m210.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers<0.21,>=0.20\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyproject_hooks\n",
            "  Using cached pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting tomli>=1.1.0\n",
            "  Using cached tomli-2.2.1-py3-none-any.whl (14 kB)\n",
            "Collecting cuda-bindings~=12.8.0\n",
            "  Downloading cuda_bindings-12.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.4/11.4 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets>=2.0.0\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 KB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill\n",
            "  Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 KB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 KB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.7\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 KB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz>=2020.1\n",
            "  Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.0/508.0 KB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 KB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading torchvision-0.20.1-cp310-cp310-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exceptiongroup>=1.0.2\n",
            "  Downloading exceptiongroup-1.2.2-py3-none-any.whl (16 kB)\n",
            "Collecting dill\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.11.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 KB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyarrow>=15.0.0\n",
            "  Downloading pyarrow-19.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->tensorrt_llm==0.16) (1.16.0)\n",
            "Collecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (146 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.1/146.1 KB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 KB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 KB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 KB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments<3.0.0,>=2.13.0\n",
            "  Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohappyeyeballs>=2.3.0\n",
            "  Downloading aiohappyeyeballs-2.4.4-py3-none-any.whl (14 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.5.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.9/241.9 KB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<6.0,>=4.0\n",
            "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting propcache>=0.2.0\n",
            "  Downloading propcache-0.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 KB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.6/124.6 KB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-25.1.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.2/63.2 KB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.17.0\n",
            "  Downloading yarl-1.18.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 KB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: tensorrt, tensorrt_cu12, mpi4py\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-10.7.0.post1-py2.py3-none-any.whl size=42191 sha256=35a8daab9dcd2ad8a6ea92e4de80da05c243b33d6a0b554b2b25a151be8b81a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/fa/e4/92fea08e9d7578dc24f26c869d2e8d967699919dac1ec5bb46\n",
            "  Building wheel for tensorrt_cu12 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt_cu12: filename=tensorrt_cu12-10.7.0.post1-py2.py3-none-any.whl size=17672 sha256=c7857450182603f5730d8e707d81c5b3a7c39daaf3ad53be5139b351b469b29f\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/fa/f1/73c5ee744e683043cfa9fcd75ed9ae627423bd89da25b9c9ba\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpi4py: filename=mpi4py-4.0.1-cp310-cp310-linux_x86_64.whl size=4266369 sha256=f4a72e2bd2105120cd889186c7e6e6607ac29465abc5736250cb3c951d197fcb\n",
            "  Stored in directory: /root/.cache/pip/wheels/3c/ca/13/13218a83854023ccec184e3af482f0f038b434aa32c19afee8\n",
            "Successfully built tensorrt tensorrt_cu12 mpi4py\n",
            "Installing collected packages: tensorrt_cu12_bindings, StrEnum, sentencepiece, pytz, nvidia-ml-py, mpmath, cuda-bindings, aenum, xxhash, urllib3, tzdata, typing-extensions, tqdm, tomli, sympy, sniffio, safetensors, regex, pyzmq, pyyaml, python-dateutil, pyproject_hooks, pynvml, pygments, pyarrow, pulp, psutil, protobuf, propcache, polygraphy, pillow, packaging, ordered-set, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, networkx, mpi4py, mdurl, MarkupSafe, lark, jiter, idna, humanfriendly, h11, fsspec, frozenlist, filelock, exceptiongroup, dill, cuda-python, colored, cloudpickle, click, charset-normalizer, certifi, attrs, async-timeout, annotated-types, aiohappyeyeballs, uvicorn, triton, tensorrt_cu12_libs, scipy, requests, pydantic-core, pandas, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, multidict, markdown-it-py, jinja2, httpcore, h5py, coloredlogs, click-option-group, build, anyio, aiosignal, yarl, tensorrt_cu12, starlette, rich, pydantic, onnx-graphsurgeon, nvidia-cusolver-cu12, huggingface-hub, httpx, torch, tokenizers, tensorrt, openai, nvidia-modelopt, fastapi, diffusers, aiohttp, transformers, torchvision, accelerate, torchprofile, datasets, optimum, evaluate, tensorrt_llm\n",
            "Successfully installed MarkupSafe-3.0.2 StrEnum-0.4.15 accelerate-1.3.0 aenum-3.1.15 aiohappyeyeballs-2.4.4 aiohttp-3.11.11 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.8.0 async-timeout-5.0.1 attrs-25.1.0 build-1.2.2.post1 certifi-2024.12.14 charset-normalizer-3.4.1 click-8.1.8 click-option-group-0.5.6 cloudpickle-3.1.1 colored-2.2.5 coloredlogs-15.0.1 cuda-bindings-12.8.0 cuda-python-12.8.0 datasets-3.2.0 diffusers-0.32.2 dill-0.3.8 evaluate-0.4.3 exceptiongroup-1.2.2 fastapi-0.115.4 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.9.0 h11-0.14.0 h5py-3.12.1 httpcore-1.0.7 httpx-0.28.1 huggingface-hub-0.28.0 humanfriendly-10.0 idna-3.10 jinja2-3.1.5 jiter-0.8.2 lark-1.2.2 markdown-it-py-3.0.0 mdurl-0.1.2 mpi4py-4.0.1 mpmath-1.3.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 ninja-1.11.1.3 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-ml-py-12.570.86 nvidia-modelopt-0.21.1 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 onnx-1.17.0 onnx-graphsurgeon-0.5.5 openai-1.54.3 optimum-1.23.3 ordered-set-4.1.0 packaging-24.2 pandas-2.2.3 pillow-10.3.0 polygraphy-0.49.14 propcache-0.2.1 protobuf-5.29.3 psutil-6.1.1 pulp-2.9.0 pyarrow-19.0.0 pydantic-2.10.6 pydantic-core-2.27.2 pygments-2.19.1 pynvml-12.0.0 pyproject_hooks-1.2.0 python-dateutil-2.9.0.post0 pytz-2024.2 pyyaml-6.0.2 pyzmq-26.2.0 regex-2024.11.6 requests-2.32.3 rich-13.9.4 safetensors-0.5.2 scipy-1.15.1 sentencepiece-0.2.0 sniffio-1.3.1 starlette-0.41.3 sympy-1.13.1 tensorrt-10.7.0.post1 tensorrt_cu12-10.7.0.post1 tensorrt_cu12_bindings-10.7.0.post1 tensorrt_cu12_libs-10.7.0.post1 tensorrt_llm-0.16.0 tokenizers-0.20.3 tomli-2.2.1 torch-2.5.1 torchprofile-0.0.4 torchvision-0.20.1 tqdm-4.67.1 transformers-4.45.1 triton-3.1.0 typing-extensions-4.12.2 tzdata-2025.1 urllib3-2.3.0 uvicorn-0.34.0 xxhash-3.5.0 yarl-1.18.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install llama-index-llms-nvidia-tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pO1ciGd8YX8J",
        "outputId": "045e0a0f-5979-4a0b-b7ca-6c7c20edf863",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-index-llms-nvidia-tensorrt\n",
            "  Downloading llama_index_llms_nvidia_tensorrt-0.3.0-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.37.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-nvidia-tensorrt) (4.45.1)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from llama-index-llms-nvidia-tensorrt) (2.5.1)\n",
            "Collecting llama-index-core<0.13.0,>=0.12.0\n",
            "  Downloading llama_index_core-0.12.14-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (3.4.2)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2.10.6)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (6.0.2)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (4.67.1)\n",
            "Collecting dirtyjson<2.0.0,>=1.0.8\n",
            "  Downloading dirtyjson-1.0.8-py3-none-any.whl (25 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (0.28.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (4.12.2)\n",
            "Collecting wrapt\n",
            "  Downloading wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.8/82.8 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2024.9.0)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (10.3.0)\n",
            "Collecting nest-asyncio<2.0.0,>=1.5.8\n",
            "  Downloading nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.26.4)\n",
            "Collecting SQLAlchemy[asyncio]>=1.4.49\n",
            "  Downloading SQLAlchemy-2.0.37-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dataclasses-json\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Collecting tenacity!=8.4.0,<10.0.0,>=8.2.0\n",
            "  Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting tiktoken>=0.3.3\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk>3.8.1\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (3.11.11)\n",
            "Collecting deprecated>=1.2.9.3\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2.32.3)\n",
            "Collecting typing-inspect>=0.8.0\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (11.2.1.3)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (3.1.0)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (2.21.5)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (12.4.127)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (10.3.5.147)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (3.17.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (3.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (1.3.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-nvidia-tensorrt) (0.5.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-nvidia-tensorrt) (24.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-nvidia-tensorrt) (0.28.0)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-nvidia-tensorrt) (0.20.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.37.0->llama-index-llms-nvidia-tensorrt) (2024.11.6)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.18.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (0.2.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (6.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2.4.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (25.1.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (5.0.1)\n",
            "Collecting joblib\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 KB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>3.8.1->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (8.1.8)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2.27.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.8.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (2024.12.14)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-3.1.1-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (599 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.5/599.5 KB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy-extensions>=0.3.0\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0\n",
            "  Downloading marshmallow-3.26.0-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.0.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (4.8.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (0.14.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<3.0.0,>=2.1.2->llama-index-llms-nvidia-tensorrt) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->llama-index-core<0.13.0,>=0.12.0->llama-index-llms-nvidia-tensorrt) (1.2.2)\n",
            "Installing collected packages: filetype, dirtyjson, wrapt, tenacity, nest-asyncio, mypy-extensions, marshmallow, joblib, greenlet, typing-inspect, tiktoken, SQLAlchemy, nltk, deprecated, dataclasses-json, llama-index-core, llama-index-llms-nvidia-tensorrt\n",
            "Successfully installed SQLAlchemy-2.0.37 dataclasses-json-0.6.7 deprecated-1.2.18 dirtyjson-1.0.8 filetype-1.2.0 greenlet-3.1.1 joblib-1.4.2 llama-index-core-0.12.14 llama-index-llms-nvidia-tensorrt-0.3.0 marshmallow-3.26.0 mypy-extensions-1.0.0 nest-asyncio-1.6.0 nltk-3.9.1 tenacity-9.0.0 tiktoken-0.8.0 typing-inspect-0.9.0 wrapt-1.17.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml==11.5.0 --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XONuhwbMYuY8",
        "outputId": "b1445b01-b6de-4d37-ffe4-ac665342cd61",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynvml==11.5.0\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.1 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 KB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "  Attempting uninstall: pynvml\n",
            "    Found existing installation: pynvml 12.0.0\n",
            "    Uninstalling pynvml-12.0.0:\n",
            "      Successfully uninstalled pynvml-12.0.0\n",
            "Successfully installed pynvml-11.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# !ls /content/drive\n",
        "!git clone --branch v0.16.0 https://github.com/NVIDIA/TensorRT-LLM.git\n",
        "!cd TensorRT-LLM/examples/gpt/ && pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "BPH6U7OPIS7Y",
        "outputId": "29328567-f0b6-403a-9387-a6a24c4245b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TensorRT-LLM'...\n",
            "remote: Enumerating objects: 34420, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 34420 (delta 4), reused 3 (delta 3), pack-reused 34403 (from 2)\u001b[K\n",
            "Receiving objects: 100% (34420/34420), 461.56 MiB | 16.00 MiB/s, done.\n",
            "Resolving deltas: 100% (24829/24829), done.\n",
            "Note: switching to '42a7b0922fc9e095f173eab9a7efa0bcdceadd0d'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "Updating files: 100% (3149/3149), done.\n",
            "Filtering content: 100% (21/21), 378.20 MiB | 30.37 MiB/s, done.\n",
            "Requirement already satisfied: tensorrt_llm==0.16.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (0.16.0)\n",
            "Collecting datasets~=2.14.5\n",
            "  Downloading datasets-2.14.7-py3-none-any.whl (520 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m520.4/520.4 KB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: evaluate~=0.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.4.3)\n",
            "Collecting rouge_score~=0.1.2\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: SentencePiece>=0.1.99 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (8.1.8)\n",
            "Requirement already satisfied: h5py==3.12.1 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.12.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (6.1.1)\n",
            "Requirement already satisfied: torch<=2.6.0a0,>=2.5.1 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.5.1)\n",
            "Requirement already satisfied: diffusers>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.32.2)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: onnx-graphsurgeon>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.5.5)\n",
            "Requirement already satisfied: nvidia-modelopt[torch]~=0.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.21.1)\n",
            "Requirement already satisfied: pulp in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.9.0)\n",
            "Requirement already satisfied: tensorrt~=10.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.7.0.post1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (26.2.0)\n",
            "Requirement already satisfied: mpi4py in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.0.1)\n",
            "Requirement already satisfied: click-option-group in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.5.6)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.23.3)\n",
            "Requirement already satisfied: mpmath>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (59.6.0)\n",
            "Requirement already satisfied: fastapi==0.115.4 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.115.4)\n",
            "Requirement already satisfied: transformers<=4.45.1,>=4.38.2 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.45.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: pynvml>=11.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (11.5.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: colored in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.2.5)\n",
            "Requirement already satisfied: pydantic>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.10.6)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.34.0)\n",
            "Requirement already satisfied: cuda-python in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.8.0)\n",
            "Requirement already satisfied: onnx>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: StrEnum in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.4.15)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.26.4)\n",
            "Requirement already satisfied: openai==1.54.3 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.54.3)\n",
            "Requirement already satisfied: ordered-set in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.1.0)\n",
            "Requirement already satisfied: polygraphy in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.49.14)\n",
            "Requirement already satisfied: accelerate>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.20.1)\n",
            "Requirement already satisfied: pillow==10.3.0 in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.3.0)\n",
            "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.37.1)\n",
            "Requirement already satisfied: build in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.2.2.post1)\n",
            "Requirement already satisfied: aenum in /usr/local/lib/python3.10/dist-packages (from tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.1.15)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.115.4->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi==0.115.4->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.41.3)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai==1.54.3->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai==1.54.3->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.54.3->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai==1.54.3->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai==1.54.3->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.8.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (19.0.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (0.70.16)\n",
            "Collecting dill<0.3.8,>=0.3.0\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 KB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec[http]<=2023.10.0,>=2023.1.0\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (24.2)\n",
            "Collecting pyarrow-hotfix\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (0.28.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets~=2.14.5->-r requirements.txt (line 2)) (3.11.11)\n",
            "Collecting absl-py\n",
            "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 KB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score~=0.1.2->-r requirements.txt (line 4)) (3.9.1)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/lib/python3/dist-packages (from rouge_score~=0.1.2->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.25.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.5.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers>=0.27.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (4.6.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.27.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers>=0.27.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (2.4.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (1.18.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (25.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (0.2.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (1.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (1.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (6.1.0)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets~=2.14.5->-r requirements.txt (line 2)) (5.0.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2024.12.14)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.10)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.11.1.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.15.1)\n",
            "Requirement already satisfied: cloudpickle>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (13.9.4)\n",
            "Requirement already satisfied: torchprofile>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.0.4)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.12.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (5.29.3)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.27.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.14.5->-r requirements.txt (line 2)) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets~=2.14.5->-r requirements.txt (line 2)) (2.3.0)\n",
            "Requirement already satisfied: tensorrt-cu12==10.7.0.post1 in /usr/local/lib/python3.10/dist-packages (from tensorrt~=10.7.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.7.0.post1)\n",
            "Requirement already satisfied: tensorrt-cu12-bindings==10.7.0.post1 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12==10.7.0.post1->tensorrt~=10.7.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.7.0.post1)\n",
            "Requirement already satisfied: tensorrt-cu12-libs==10.7.0.post1 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12==10.7.0.post1->tensorrt~=10.7.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.7.0.post1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12 in /usr/local/lib/python3.10/dist-packages (from tensorrt-cu12-libs==10.7.0.post1->tensorrt-cu12==10.7.0.post1->tensorrt~=10.7.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.3.5.147)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.4.127)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (9.1.0.70)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.1,>=4.38.2->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.20.3)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: cuda-bindings~=12.8.0 in /usr/local/lib/python3.10/dist-packages (from cuda-python->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (12.8.0)\n",
            "Collecting multiprocess\n",
            "  Using cached multiprocess-0.70.17-py310-none-any.whl (134 kB)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 KB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->rouge_score~=0.1.2->-r requirements.txt (line 4)) (1.4.2)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (15.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2025.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2024.2)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai==1.54.3->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch<=2.6.0a0,>=2.5.1->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.0.2)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (2.19.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->nvidia-modelopt[torch]~=0.21.0->tensorrt_llm==0.16.0->-r requirements.txt (line 1)) (0.1.2)\n",
            "Building wheels for collected packages: rouge_score\n",
            "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24955 sha256=4e60afbca94bccc3187714fb59094dbf566bfeefd516f2cd1dc28634649888e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge_score\n",
            "Installing collected packages: pyarrow-hotfix, fsspec, dill, absl-py, rouge_score, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.8\n",
            "    Uninstalling dill-0.3.8:\n",
            "      Successfully uninstalled dill-0.3.8\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.16\n",
            "    Uninstalling multiprocess-0.70.16:\n",
            "      Successfully uninstalled multiprocess-0.70.16\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 3.2.0\n",
            "    Uninstalling datasets-3.2.0:\n",
            "      Successfully uninstalled datasets-3.2.0\n",
            "Successfully installed absl-py-2.1.0 datasets-2.14.7 dill-0.3.7 fsspec-2023.10.0 multiprocess-0.70.15 pyarrow-hotfix-0.6 rouge_score-0.1.2\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38axpVzXJO-k",
        "outputId": "79fff83b-9a68-48b4-d912-ad4d2bf762cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  TensorRT-LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!git clone --branch master https://huggingface.co/swetha097/vicuna_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzT0tVc9hOKO",
        "outputId": "70476e13-aec4-4e2b-cc73-5f53c097a7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'vicuna_model'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 16 (delta 0), reused 0 (delta 0), pack-reused 3 (from 1)\u001b[K\n",
            "Unpacking objects: 100% (16/16), 222.71 KiB | 1000.00 KiB/s, done.\n",
            "Filtering content: 100% (3/3), 5.11 GiB | 2.40 MiB/s, done.\n",
            "Encountered 3 file(s) that may not have been copied correctly on Windows:\n",
            "\tpytorch_model-00003-of-00003.bin\n",
            "\tpytorch_model-00001-of-00003.bin\n",
            "\tpytorch_model-00002-of-00003.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n",
        "!python3 -c \"import tensorrt_llm\"\n",
        "!du -h\n",
        "# !cd vicuna_model/ && git count-objects -vH && git lfs fetch --all && git lfs ls-files"
      ],
      "metadata": {
        "id": "7jdmalyGakDe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb081080-2c92-4ab4-bebf-2eda438fcdc3",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  TensorRT-LLM  vicuna_model\n",
            "[TensorRT-LLM] TensorRT-LLM version: 0.16.0\n",
            "80K\t./.config/logs/2025.01.28\n",
            "84K\t./.config/logs\n",
            "8.0K\t./.config/configurations\n",
            "140K\t./.config\n",
            "44K\t./TensorRT-LLM/scripts\n",
            "12K\t./TensorRT-LLM/.github/workflows\n",
            "12K\t./TensorRT-LLM/.github/ISSUE_TEMPLATE\n",
            "28K\t./TensorRT-LLM/.github\n",
            "36K\t./TensorRT-LLM/examples/bindings/executor\n",
            "40K\t./TensorRT-LLM/examples/bindings\n",
            "60K\t./TensorRT-LLM/examples/llm-api\n",
            "16K\t./TensorRT-LLM/examples/draft_target_model\n",
            "32K\t./TensorRT-LLM/examples/quantization\n",
            "20K\t./TensorRT-LLM/examples/cpp_library\n",
            "32K\t./TensorRT-LLM/examples/deepseek_v2\n",
            "16K\t./TensorRT-LLM/examples/python_plugin/plugin_lib\n",
            "36K\t./TensorRT-LLM/examples/python_plugin\n",
            "40K\t./TensorRT-LLM/examples/eagle\n",
            "8.0K\t./TensorRT-LLM/examples/blip2\n",
            "20K\t./TensorRT-LLM/examples/model_api\n",
            "88K\t./TensorRT-LLM/examples/sdxl\n",
            "52K\t./TensorRT-LLM/examples/recurrentgemma\n",
            "28K\t./TensorRT-LLM/examples/commandr\n",
            "16K\t./TensorRT-LLM/examples/nemotron\n",
            "52K\t./TensorRT-LLM/examples/qwen\n",
            "128K\t./TensorRT-LLM/examples/llama\n",
            "36K\t./TensorRT-LLM/examples/baichuan\n",
            "88K\t./TensorRT-LLM/examples/gpt\n",
            "12K\t./TensorRT-LLM/examples/smaug\n",
            "44K\t./TensorRT-LLM/examples/internlm2\n",
            "44K\t./TensorRT-LLM/examples/dbrx\n",
            "64K\t./TensorRT-LLM/examples/bloom\n",
            "68K\t./TensorRT-LLM/examples/chatglm\n",
            "76K\t./TensorRT-LLM/examples/multimodal\n",
            "20K\t./TensorRT-LLM/examples/mixtral\n",
            "40K\t./TensorRT-LLM/examples/redrafter\n",
            "28K\t./TensorRT-LLM/examples/apps\n",
            "32K\t./TensorRT-LLM/examples/gptj\n",
            "36K\t./TensorRT-LLM/examples/opt\n",
            "32K\t./TensorRT-LLM/examples/openai_triton/plugin_autogen\n",
            "88K\t./TensorRT-LLM/examples/openai_triton/manual_plugin\n",
            "128K\t./TensorRT-LLM/examples/openai_triton\n",
            "124K\t./TensorRT-LLM/examples/enc_dec\n",
            "32K\t./TensorRT-LLM/examples/falcon\n",
            "12K\t./TensorRT-LLM/examples/exaone\n",
            "8.0K\t./TensorRT-LLM/examples/bert/base_with_attention_plugin_benchmark\n",
            "8.0K\t./TensorRT-LLM/examples/bert/large_with_attention_plugin_benchmark\n",
            "8.0K\t./TensorRT-LLM/examples/bert/large_benchmark\n",
            "8.0K\t./TensorRT-LLM/examples/bert/base_benchmark\n",
            "80K\t./TensorRT-LLM/examples/bert\n",
            "16K\t./TensorRT-LLM/examples/jais\n",
            "60K\t./TensorRT-LLM/examples/mpt\n",
            "24K\t./TensorRT-LLM/examples/phi\n",
            "28K\t./TensorRT-LLM/examples/internlm\n",
            "24K\t./TensorRT-LLM/examples/deepseek_v1\n",
            "16K\t./TensorRT-LLM/examples/lookahead\n",
            "16K\t./TensorRT-LLM/examples/sample_weight_stripping\n",
            "2.9M\t./TensorRT-LLM/examples/qwenvl/pics\n",
            "3.0M\t./TensorRT-LLM/examples/qwenvl\n",
            "24K\t./TensorRT-LLM/examples/nemotron_nas\n",
            "28K\t./TensorRT-LLM/examples/grok\n",
            "24K\t./TensorRT-LLM/examples/cogvlm\n",
            "40K\t./TensorRT-LLM/examples/medusa\n",
            "12K\t./TensorRT-LLM/examples/skywork\n",
            "32K\t./TensorRT-LLM/examples/prompt_lookup\n",
            "12K\t./TensorRT-LLM/examples/whisper/distil_whisper\n",
            "104K\t./TensorRT-LLM/examples/whisper\n",
            "1.6M\t./TensorRT-LLM/examples/dit/figs\n",
            "1.6M\t./TensorRT-LLM/examples/dit\n",
            "96K\t./TensorRT-LLM/examples/cpp/executor\n",
            "100K\t./TensorRT-LLM/examples/cpp\n",
            "12K\t./TensorRT-LLM/examples/arctic\n",
            "28K\t./TensorRT-LLM/examples/mllama\n",
            "48K\t./TensorRT-LLM/examples/gemma\n",
            "28K\t./TensorRT-LLM/examples/infinitebench\n",
            "28K\t./TensorRT-LLM/examples/mamba\n",
            "60K\t./TensorRT-LLM/examples/gptneox\n",
            "7.0M\t./TensorRT-LLM/examples\n",
            "52K\t./TensorRT-LLM/benchmarks/cpp/utils\n",
            "256K\t./TensorRT-LLM/benchmarks/cpp\n",
            "108K\t./TensorRT-LLM/benchmarks/python\n",
            "372K\t./TensorRT-LLM/benchmarks\n",
            "4.0K\t./TensorRT-LLM/3rdparty/cutlass\n",
            "4.0K\t./TensorRT-LLM/3rdparty/ucxx\n",
            "4.0K\t./TensorRT-LLM/3rdparty/NVTX\n",
            "4.0K\t./TensorRT-LLM/3rdparty/cxxopts\n",
            "4.0K\t./TensorRT-LLM/3rdparty/json\n",
            "4.0K\t./TensorRT-LLM/3rdparty/pybind11\n",
            "4.0K\t./TensorRT-LLM/3rdparty/xgrammar\n",
            "32K\t./TensorRT-LLM/3rdparty\n",
            "44K\t./TensorRT-LLM/docker/common\n",
            "68K\t./TensorRT-LLM/docker\n",
            "12K\t./TensorRT-LLM/windows/examples/llama\n",
            "16K\t./TensorRT-LLM/windows/examples\n",
            "20K\t./TensorRT-LLM/windows/docker\n",
            "64K\t./TensorRT-LLM/windows\n",
            "12K\t./TensorRT-LLM/docs/source/llm-api\n",
            "28K\t./TensorRT-LLM/docs/source/python-api\n",
            "76K\t./TensorRT-LLM/docs/source/architecture\n",
            "656K\t./TensorRT-LLM/docs/source/blogs/media\n",
            "696K\t./TensorRT-LLM/docs/source/blogs\n",
            "36K\t./TensorRT-LLM/docs/source/installation\n",
            "8.0K\t./TensorRT-LLM/docs/source/_templates\n",
            "20K\t./TensorRT-LLM/docs/source/llm-api-examples\n",
            "64K\t./TensorRT-LLM/docs/source/media\n",
            "132K\t./TensorRT-LLM/docs/source/advanced\n",
            "72K\t./TensorRT-LLM/docs/source/performance\n",
            "12K\t./TensorRT-LLM/docs/source/commands\n",
            "56K\t./TensorRT-LLM/docs/source/reference\n",
            "1.3M\t./TensorRT-LLM/docs/source\n",
            "1.4M\t./TensorRT-LLM/docs\n",
            "40K\t./TensorRT-LLM/tensorrt_llm/bench/build\n",
            "20K\t./TensorRT-LLM/tensorrt_llm/bench/utils\n",
            "32K\t./TensorRT-LLM/tensorrt_llm/bench/benchmark/utils\n",
            "56K\t./TensorRT-LLM/tensorrt_llm/bench/benchmark\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/bench/dataclasses\n",
            "172K\t./TensorRT-LLM/tensorrt_llm/bench\n",
            "180K\t./TensorRT-LLM/tensorrt_llm/llmapi\n",
            "264K\t./TensorRT-LLM/tensorrt_llm/quantization\n",
            "48K\t./TensorRT-LLM/tensorrt_llm/tools/plugin_gen/templates\n",
            "104K\t./TensorRT-LLM/tensorrt_llm/tools/plugin_gen\n",
            "172K\t./TensorRT-LLM/tensorrt_llm/tools\n",
            "36K\t./TensorRT-LLM/tensorrt_llm/plugin\n",
            "28K\t./TensorRT-LLM/tensorrt_llm/models/unet/pp\n",
            "112K\t./TensorRT-LLM/tensorrt_llm/models/unet\n",
            "48K\t./TensorRT-LLM/tensorrt_llm/models/deepseek_v2\n",
            "64K\t./TensorRT-LLM/tensorrt_llm/models/eagle\n",
            "36K\t./TensorRT-LLM/tensorrt_llm/models/recurrentgemma\n",
            "20K\t./TensorRT-LLM/tensorrt_llm/models/commandr\n",
            "108K\t./TensorRT-LLM/tensorrt_llm/models/qwen\n",
            "152K\t./TensorRT-LLM/tensorrt_llm/models/llama\n",
            "64K\t./TensorRT-LLM/tensorrt_llm/models/baichuan\n",
            "104K\t./TensorRT-LLM/tensorrt_llm/models/gpt\n",
            "20K\t./TensorRT-LLM/tensorrt_llm/models/dbrx\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/bloom\n",
            "64K\t./TensorRT-LLM/tensorrt_llm/models/chatglm\n",
            "68K\t./TensorRT-LLM/tensorrt_llm/models/redrafter\n",
            "28K\t./TensorRT-LLM/tensorrt_llm/models/gptj\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/opt\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/models/phi3\n",
            "100K\t./TensorRT-LLM/tensorrt_llm/models/enc_dec\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/models/falcon\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/models/bert\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/mpt\n",
            "28K\t./TensorRT-LLM/tensorrt_llm/models/phi\n",
            "44K\t./TensorRT-LLM/tensorrt_llm/models/deepseek_v1\n",
            "76K\t./TensorRT-LLM/tensorrt_llm/models/nemotron_nas\n",
            "44K\t./TensorRT-LLM/tensorrt_llm/models/grok\n",
            "36K\t./TensorRT-LLM/tensorrt_llm/models/cogvlm\n",
            "56K\t./TensorRT-LLM/tensorrt_llm/models/medusa\n",
            "24K\t./TensorRT-LLM/tensorrt_llm/models/dit\n",
            "84K\t./TensorRT-LLM/tensorrt_llm/models/mllama\n",
            "40K\t./TensorRT-LLM/tensorrt_llm/models/gemma/utils\n",
            "164K\t./TensorRT-LLM/tensorrt_llm/models/gemma\n",
            "56K\t./TensorRT-LLM/tensorrt_llm/models/mamba\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/gptneox\n",
            "2.0M\t./TensorRT-LLM/tensorrt_llm/models\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/runtime/memory_pools\n",
            "512K\t./TensorRT-LLM/tensorrt_llm/runtime\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/commands\n",
            "40K\t./TensorRT-LLM/tensorrt_llm/auto_parallel/tensor_parallel/plugin_nodes\n",
            "268K\t./TensorRT-LLM/tensorrt_llm/auto_parallel/tensor_parallel\n",
            "596K\t./TensorRT-LLM/tensorrt_llm/auto_parallel\n",
            "272K\t./TensorRT-LLM/tensorrt_llm/layers\n",
            "48K\t./TensorRT-LLM/tensorrt_llm/serve\n",
            "4.9M\t./TensorRT-LLM/tensorrt_llm\n",
            "116K\t./TensorRT-LLM/tests/bindings\n",
            "32K\t./TensorRT-LLM/tests/llmapi/_perf_evaluator\n",
            "48K\t./TensorRT-LLM/tests/llmapi/apps\n",
            "240K\t./TensorRT-LLM/tests/llmapi\n",
            "180K\t./TensorRT-LLM/tests/quantization\n",
            "16K\t./TensorRT-LLM/tests/python_plugin\n",
            "20K\t./TensorRT-LLM/tests/tools/plugin_gen\n",
            "24K\t./TensorRT-LLM/tests/tools\n",
            "32K\t./TensorRT-LLM/tests/model_api\n",
            "44K\t./TensorRT-LLM/tests/utils\n",
            "232K\t./TensorRT-LLM/tests/attention\n",
            "440K\t./TensorRT-LLM/tests/functional\n",
            "204K\t./TensorRT-LLM/tests/model/eagle\n",
            "96K\t./TensorRT-LLM/tests/model/redrafter\n",
            "604K\t./TensorRT-LLM/tests/model\n",
            "2.2M\t./TensorRT-LLM/tests\n",
            "20K\t./TensorRT-LLM/cpp/cmake/modules\n",
            "8.0K\t./TensorRT-LLM/cpp/cmake/utils\n",
            "8.0K\t./TensorRT-LLM/cpp/cmake/templates\n",
            "40K\t./TensorRT-LLM/cpp/cmake\n",
            "19M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager/aarch64-linux-gnu\n",
            "48M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager/x86_64-windows-msvc\n",
            "15M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager/x86_64-linux-gnu\n",
            "81M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager\n",
            "5.3M\t./TensorRT-LLM/cpp/tensorrt_llm/executor/aarch64-linux-gnu\n",
            "25M\t./TensorRT-LLM/cpp/tensorrt_llm/executor/x86_64-windows-msvc\n",
            "7.2M\t./TensorRT-LLM/cpp/tensorrt_llm/executor/x86_64-linux-gnu\n",
            "37M\t./TensorRT-LLM/cpp/tensorrt_llm/executor\n",
            "12K\t./TensorRT-LLM/cpp/tensorrt_llm/executor_worker\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lowLatencyGemmSwigluPlugin\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/quantizeTensorPlugin\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/loraPlugin\n",
            "44K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/weightOnlyGroupwiseQuantMatmulPlugin\n",
            "172K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gptAttentionCommon\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/qserveGemmPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/cumsumLastDimPlugin\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gemmSwigluPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/topkLastDimPlugin\n",
            "132K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/eaglePlugin\n",
            "28K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/quantizePerTokenPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/mambaConv1dPlugin\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/rmsnormQuantizationPlugin\n",
            "76K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/mixtureOfExperts\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/weightOnlyQuantMatmulPlugin\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/api\n",
            "28K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/cudaStreamPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lowLatencyGemmPlugin\n",
            "96K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/ncclPlugin\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/selectiveScanPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lookupPlugin\n",
            "84K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/common\n",
            "48K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/bertAttentionPlugin\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/identityPlugin\n",
            "28K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/cpSplitPlugin\n",
            "92K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gptAttentionPlugin\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gemmPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/fp8RowwiseGemmPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/layernormQuantizationPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lruPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/smoothQuantGemmPlugin\n",
            "1.5M\t./TensorRT-LLM/cpp/tensorrt_llm/plugins\n",
            "16K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/transform/threadblock\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/transform\n",
            "8.0K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue/thread\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue/collective\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue/threadblock\n",
            "76K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue\n",
            "292K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/kernel\n",
            "48K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/warp\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/collective/builders\n",
            "196K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/collective\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/device\n",
            "208K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/threadblock\n",
            "788K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm\n",
            "12K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/util\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/arch\n",
            "972K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions\n",
            "976K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include\n",
            "980K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions\n",
            "292K\t./TensorRT-LLM/cpp/tensorrt_llm/common\n",
            "60K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/selectiveScan/instantiation\n",
            "344K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/selectiveScan\n",
            "79M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/aarch64-linux-gnu\n",
            "1.1M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/x86_64-windows-msvc\n",
            "81M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/x86_64-linux-gnu\n",
            "8.0K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/include\n",
            "161M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper\n",
            "161M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT\n",
            "232K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/instantiation\n",
            "118M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/cubin\n",
            "279M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention\n",
            "156K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/weightOnlyBatchedGemv\n",
            "156K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/mixtureOfExperts\n",
            "712M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/contextFusedMultiHeadAttention/cubin\n",
            "712M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/contextFusedMultiHeadAttention\n",
            "37M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/aarch64-linux-gnu\n",
            "2.6M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/x86_64-windows-msvc\n",
            "62M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/x86_64-linux-gnu\n",
            "16K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/include\n",
            "101M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/lora\n",
            "116K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/unfusedAttentionKernels\n",
            "68K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fp8_rowwise_gemm\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/moe_gemm/launchers\n",
            "160K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/moe_gemm\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fused_gated_gemm\n",
            "44K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/int8_gemm\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fpA_intB_gemm/launchers\n",
            "152K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fpA_intB_gemm\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/python\n",
            "568K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels\n",
            "304K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/speculativeDecoding\n",
            "148K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/userbuffers\n",
            "76K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/beamSearchKernels\n",
            "1.1G\t./TensorRT-LLM/cpp/tensorrt_llm/kernels\n",
            "184K\t./TensorRT-LLM/cpp/tensorrt_llm/thop\n",
            "60K\t./TensorRT-LLM/cpp/tensorrt_llm/runtime/utils\n",
            "784K\t./TensorRT-LLM/cpp/tensorrt_llm/runtime\n",
            "112K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/batch_manager\n",
            "116K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/executor\n",
            "16K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/common\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/runtime\n",
            "308K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind\n",
            "408K\t./TensorRT-LLM/cpp/tensorrt_llm/layers\n",
            "1.2G\t./TensorRT-LLM/cpp/tensorrt_llm\n",
            "280K\t./TensorRT-LLM/cpp/include/tensorrt_llm/batch_manager\n",
            "152K\t./TensorRT-LLM/cpp/include/tensorrt_llm/executor\n",
            "8.0K\t./TensorRT-LLM/cpp/include/tensorrt_llm/plugins/api\n",
            "12K\t./TensorRT-LLM/cpp/include/tensorrt_llm/plugins\n",
            "108K\t./TensorRT-LLM/cpp/include/tensorrt_llm/common\n",
            "12K\t./TensorRT-LLM/cpp/include/tensorrt_llm/kernels\n",
            "16K\t./TensorRT-LLM/cpp/include/tensorrt_llm/runtime/utils\n",
            "344K\t./TensorRT-LLM/cpp/include/tensorrt_llm/runtime\n",
            "8.0K\t./TensorRT-LLM/cpp/include/tensorrt_llm/layers\n",
            "920K\t./TensorRT-LLM/cpp/include/tensorrt_llm\n",
            "924K\t./TensorRT-LLM/cpp/include\n",
            "28K\t./TensorRT-LLM/cpp/tests/utils\n",
            "60K\t./TensorRT-LLM/cpp/tests/common\n",
            "16K\t./TensorRT-LLM/cpp/tests/kernels/smoothQuant\n",
            "140K\t./TensorRT-LLM/cpp/tests/kernels/sampling\n",
            "48K\t./TensorRT-LLM/cpp/tests/kernels/fused_gated_gemm\n",
            "20K\t./TensorRT-LLM/cpp/tests/kernels/cudaCoreGemm\n",
            "24K\t./TensorRT-LLM/cpp/tests/kernels/weightOnly\n",
            "20K\t./TensorRT-LLM/cpp/tests/kernels/allReduce\n",
            "568K\t./TensorRT-LLM/cpp/tests/kernels\n",
            "8.0K\t./TensorRT-LLM/cpp/tests/thop\n",
            "344K\t./TensorRT-LLM/cpp/tests/runtime\n",
            "484K\t./TensorRT-LLM/cpp/tests/layers\n",
            "224K\t./TensorRT-LLM/cpp/tests/resources/scripts\n",
            "44K\t./TensorRT-LLM/cpp/tests/resources/data\n",
            "32K\t./TensorRT-LLM/cpp/tests/resources/models\n",
            "308K\t./TensorRT-LLM/cpp/tests/resources\n",
            "1.8M\t./TensorRT-LLM/cpp/tests\n",
            "76K\t./TensorRT-LLM/cpp/micro_benchmarks\n",
            "1.2G\t./TensorRT-LLM/cpp\n",
            "4.0K\t./TensorRT-LLM/.git/objects/info\n",
            "463M\t./TensorRT-LLM/.git/objects/pack\n",
            "463M\t./TensorRT-LLM/.git/objects\n",
            "8.0K\t./TensorRT-LLM/.git/logs/refs/remotes/origin\n",
            "12K\t./TensorRT-LLM/.git/logs/refs/remotes\n",
            "16K\t./TensorRT-LLM/.git/logs/refs\n",
            "24K\t./TensorRT-LLM/.git/logs\n",
            "8.0K\t./TensorRT-LLM/.git/info\n",
            "4.0K\t./TensorRT-LLM/.git/branches\n",
            "80K\t./TensorRT-LLM/.git/hooks\n",
            "8.0K\t./TensorRT-LLM/.git/refs/remotes/origin\n",
            "12K\t./TensorRT-LLM/.git/refs/remotes\n",
            "4.0K\t./TensorRT-LLM/.git/refs/tags\n",
            "4.0K\t./TensorRT-LLM/.git/refs/heads\n",
            "24K\t./TensorRT-LLM/.git/refs\n",
            "48M\t./TensorRT-LLM/.git/lfs/objects/64/76\n",
            "48M\t./TensorRT-LLM/.git/lfs/objects/64\n",
            "2.6M\t./TensorRT-LLM/.git/lfs/objects/e5/23\n",
            "2.6M\t./TensorRT-LLM/.git/lfs/objects/e5\n",
            "3.7M\t./TensorRT-LLM/.git/lfs/objects/2f/a6\n",
            "3.7M\t./TensorRT-LLM/.git/lfs/objects/2f\n",
            "24K\t./TensorRT-LLM/.git/lfs/objects/ed/a1\n",
            "28K\t./TensorRT-LLM/.git/lfs/objects/ed\n",
            "3.6M\t./TensorRT-LLM/.git/lfs/objects/5a/8a\n",
            "3.6M\t./TensorRT-LLM/.git/lfs/objects/5a\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/a6/e7\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/a6\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/95/c9\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/95\n",
            "7.4M\t./TensorRT-LLM/.git/lfs/objects/c5/23\n",
            "7.4M\t./TensorRT-LLM/.git/lfs/objects/c5\n",
            "81M\t./TensorRT-LLM/.git/lfs/objects/2d/f5\n",
            "81M\t./TensorRT-LLM/.git/lfs/objects/2d\n",
            "7.5M\t./TensorRT-LLM/.git/lfs/objects/50/cc\n",
            "7.5M\t./TensorRT-LLM/.git/lfs/objects/50\n",
            "1.9M\t./TensorRT-LLM/.git/lfs/objects/86/d1\n",
            "1.9M\t./TensorRT-LLM/.git/lfs/objects/86\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/79/45\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/79\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/ae/74\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/ae\n",
            "25M\t./TensorRT-LLM/.git/lfs/objects/af/7b\n",
            "25M\t./TensorRT-LLM/.git/lfs/objects/af\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/0c/c7\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/0c\n",
            "31M\t./TensorRT-LLM/.git/lfs/objects/db/6c\n",
            "31M\t./TensorRT-LLM/.git/lfs/objects/db\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/e4/d5\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/e4\n",
            "32M\t./TensorRT-LLM/.git/lfs/objects/b6/1c\n",
            "32M\t./TensorRT-LLM/.git/lfs/objects/b6\n",
            "79M\t./TensorRT-LLM/.git/lfs/objects/53/9c\n",
            "79M\t./TensorRT-LLM/.git/lfs/objects/53\n",
            "8.0K\t./TensorRT-LLM/.git/lfs/objects/02/bd\n",
            "12K\t./TensorRT-LLM/.git/lfs/objects/02\n",
            "1.1M\t./TensorRT-LLM/.git/lfs/objects/62/d0\n",
            "1.1M\t./TensorRT-LLM/.git/lfs/objects/62\n",
            "379M\t./TensorRT-LLM/.git/lfs/objects\n",
            "4.0K\t./TensorRT-LLM/.git/lfs/incomplete\n",
            "4.0K\t./TensorRT-LLM/.git/lfs/tmp\n",
            "379M\t./TensorRT-LLM/.git/lfs\n",
            "842M\t./TensorRT-LLM/.git\n",
            "2.1G\t./TensorRT-LLM\n",
            "8.0K\t./vicuna_model/.git/objects/60\n",
            "8.0K\t./vicuna_model/.git/objects/a4\n",
            "8.0K\t./vicuna_model/.git/objects/0e\n",
            "248K\t./vicuna_model/.git/objects/22\n",
            "8.0K\t./vicuna_model/.git/objects/54\n",
            "8.0K\t./vicuna_model/.git/objects/d2\n",
            "8.0K\t./vicuna_model/.git/objects/7c\n",
            "8.0K\t./vicuna_model/.git/objects/13\n",
            "8.0K\t./vicuna_model/.git/objects/a6\n",
            "8.0K\t./vicuna_model/.git/objects/ff\n",
            "8.0K\t./vicuna_model/.git/objects/42\n",
            "8.0K\t./vicuna_model/.git/objects/dc\n",
            "4.0K\t./vicuna_model/.git/objects/info\n",
            "8.0K\t./vicuna_model/.git/objects/4e\n",
            "8.0K\t./vicuna_model/.git/objects/c9\n",
            "8.0K\t./vicuna_model/.git/objects/ec\n",
            "4.0K\t./vicuna_model/.git/objects/pack\n",
            "8.0K\t./vicuna_model/.git/objects/fa\n",
            "380K\t./vicuna_model/.git/objects\n",
            "8.0K\t./vicuna_model/.git/logs/refs/remotes/origin\n",
            "12K\t./vicuna_model/.git/logs/refs/remotes\n",
            "8.0K\t./vicuna_model/.git/logs/refs/heads\n",
            "24K\t./vicuna_model/.git/logs/refs\n",
            "32K\t./vicuna_model/.git/logs\n",
            "8.0K\t./vicuna_model/.git/info\n",
            "4.0K\t./vicuna_model/.git/branches\n",
            "80K\t./vicuna_model/.git/hooks\n",
            "8.0K\t./vicuna_model/.git/refs/remotes/origin\n",
            "12K\t./vicuna_model/.git/refs/remotes\n",
            "4.0K\t./vicuna_model/.git/refs/tags\n",
            "8.0K\t./vicuna_model/.git/refs/heads\n",
            "28K\t./vicuna_model/.git/refs\n",
            "6.7G\t./vicuna_model/.git/lfs/objects/cf/b8\n",
            "6.7G\t./vicuna_model/.git/lfs/objects/cf\n",
            "9.3G\t./vicuna_model/.git/lfs/objects/bd/35\n",
            "9.3G\t./vicuna_model/.git/lfs/objects/bd\n",
            "9.2G\t./vicuna_model/.git/lfs/objects/a1/4c\n",
            "9.2G\t./vicuna_model/.git/lfs/objects/a1\n",
            "26G\t./vicuna_model/.git/lfs/objects\n",
            "4.0K\t./vicuna_model/.git/lfs/incomplete\n",
            "4.0K\t./vicuna_model/.git/lfs/tmp\n",
            "26G\t./vicuna_model/.git/lfs\n",
            "26G\t./vicuna_model/.git\n",
            "51G\t./vicuna_model\n",
            "55M\t./sample_data\n",
            "53G\t.\n",
            "count: 16\n",
            "size: 304.00 KiB\n",
            "in-pack: 0\n",
            "packs: 0\n",
            "size-pack: 0 bytes\n",
            "prune-packable: 0\n",
            "garbage: 0\n",
            "size-garbage: 0 bytes\n",
            "fetch: 3 object(s) found, done.\n",
            "fetch: Fetching all references...\n",
            "a14c5dc0a2 * pytorch_model-00001-of-00003.bin\n",
            "bd357f1851 * pytorch_model-00002-of-00003.bin\n",
            "cfb8799707 * pytorch_model-00003-of-00003.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Convert checkpoints to a format accepted by tensorrt-llm"
      ],
      "metadata": {
        "id": "f1hUTDZJ4tr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir TensorRT-LLM/tllm_checkpoint_1gpu_fp16\n",
        "!rm -r vicuna_model/.git/\n",
        "!ls\n",
        "!du -h\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHvDrVAn4z4X",
        "outputId": "7cbe4287-2e94-4672-ecd5-d04964e3902b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘TensorRT-LLM/tllm_checkpoint_1gpu_fp16’: File exists\n",
            "sample_data  TensorRT-LLM  vicuna_model\n",
            "80K\t./.config/logs/2025.01.28\n",
            "84K\t./.config/logs\n",
            "8.0K\t./.config/configurations\n",
            "140K\t./.config\n",
            "4.0K\t./TensorRT-LLM/tllm_checkpoint_1gpu_fp16\n",
            "44K\t./TensorRT-LLM/scripts\n",
            "12K\t./TensorRT-LLM/.github/workflows\n",
            "12K\t./TensorRT-LLM/.github/ISSUE_TEMPLATE\n",
            "28K\t./TensorRT-LLM/.github\n",
            "36K\t./TensorRT-LLM/examples/bindings/executor\n",
            "40K\t./TensorRT-LLM/examples/bindings\n",
            "60K\t./TensorRT-LLM/examples/llm-api\n",
            "16K\t./TensorRT-LLM/examples/draft_target_model\n",
            "32K\t./TensorRT-LLM/examples/quantization\n",
            "20K\t./TensorRT-LLM/examples/cpp_library\n",
            "32K\t./TensorRT-LLM/examples/deepseek_v2\n",
            "16K\t./TensorRT-LLM/examples/python_plugin/plugin_lib\n",
            "36K\t./TensorRT-LLM/examples/python_plugin\n",
            "40K\t./TensorRT-LLM/examples/eagle\n",
            "8.0K\t./TensorRT-LLM/examples/blip2\n",
            "20K\t./TensorRT-LLM/examples/model_api\n",
            "88K\t./TensorRT-LLM/examples/sdxl\n",
            "52K\t./TensorRT-LLM/examples/recurrentgemma\n",
            "28K\t./TensorRT-LLM/examples/commandr\n",
            "16K\t./TensorRT-LLM/examples/nemotron\n",
            "52K\t./TensorRT-LLM/examples/qwen\n",
            "128K\t./TensorRT-LLM/examples/llama\n",
            "36K\t./TensorRT-LLM/examples/baichuan\n",
            "88K\t./TensorRT-LLM/examples/gpt\n",
            "12K\t./TensorRT-LLM/examples/smaug\n",
            "44K\t./TensorRT-LLM/examples/internlm2\n",
            "44K\t./TensorRT-LLM/examples/dbrx\n",
            "64K\t./TensorRT-LLM/examples/bloom\n",
            "68K\t./TensorRT-LLM/examples/chatglm\n",
            "76K\t./TensorRT-LLM/examples/multimodal\n",
            "20K\t./TensorRT-LLM/examples/mixtral\n",
            "40K\t./TensorRT-LLM/examples/redrafter\n",
            "28K\t./TensorRT-LLM/examples/apps\n",
            "32K\t./TensorRT-LLM/examples/gptj\n",
            "36K\t./TensorRT-LLM/examples/opt\n",
            "32K\t./TensorRT-LLM/examples/openai_triton/plugin_autogen\n",
            "88K\t./TensorRT-LLM/examples/openai_triton/manual_plugin\n",
            "128K\t./TensorRT-LLM/examples/openai_triton\n",
            "124K\t./TensorRT-LLM/examples/enc_dec\n",
            "32K\t./TensorRT-LLM/examples/falcon\n",
            "12K\t./TensorRT-LLM/examples/exaone\n",
            "8.0K\t./TensorRT-LLM/examples/bert/base_with_attention_plugin_benchmark\n",
            "8.0K\t./TensorRT-LLM/examples/bert/large_with_attention_plugin_benchmark\n",
            "8.0K\t./TensorRT-LLM/examples/bert/large_benchmark\n",
            "8.0K\t./TensorRT-LLM/examples/bert/base_benchmark\n",
            "80K\t./TensorRT-LLM/examples/bert\n",
            "16K\t./TensorRT-LLM/examples/jais\n",
            "60K\t./TensorRT-LLM/examples/mpt\n",
            "24K\t./TensorRT-LLM/examples/phi\n",
            "28K\t./TensorRT-LLM/examples/internlm\n",
            "24K\t./TensorRT-LLM/examples/deepseek_v1\n",
            "16K\t./TensorRT-LLM/examples/lookahead\n",
            "16K\t./TensorRT-LLM/examples/sample_weight_stripping\n",
            "2.9M\t./TensorRT-LLM/examples/qwenvl/pics\n",
            "3.0M\t./TensorRT-LLM/examples/qwenvl\n",
            "24K\t./TensorRT-LLM/examples/nemotron_nas\n",
            "28K\t./TensorRT-LLM/examples/grok\n",
            "24K\t./TensorRT-LLM/examples/cogvlm\n",
            "40K\t./TensorRT-LLM/examples/medusa\n",
            "12K\t./TensorRT-LLM/examples/skywork\n",
            "32K\t./TensorRT-LLM/examples/prompt_lookup\n",
            "12K\t./TensorRT-LLM/examples/whisper/distil_whisper\n",
            "104K\t./TensorRT-LLM/examples/whisper\n",
            "1.6M\t./TensorRT-LLM/examples/dit/figs\n",
            "1.6M\t./TensorRT-LLM/examples/dit\n",
            "96K\t./TensorRT-LLM/examples/cpp/executor\n",
            "100K\t./TensorRT-LLM/examples/cpp\n",
            "12K\t./TensorRT-LLM/examples/arctic\n",
            "28K\t./TensorRT-LLM/examples/mllama\n",
            "48K\t./TensorRT-LLM/examples/gemma\n",
            "28K\t./TensorRT-LLM/examples/infinitebench\n",
            "28K\t./TensorRT-LLM/examples/mamba\n",
            "60K\t./TensorRT-LLM/examples/gptneox\n",
            "7.0M\t./TensorRT-LLM/examples\n",
            "52K\t./TensorRT-LLM/benchmarks/cpp/utils\n",
            "256K\t./TensorRT-LLM/benchmarks/cpp\n",
            "108K\t./TensorRT-LLM/benchmarks/python\n",
            "372K\t./TensorRT-LLM/benchmarks\n",
            "4.0K\t./TensorRT-LLM/3rdparty/cutlass\n",
            "4.0K\t./TensorRT-LLM/3rdparty/ucxx\n",
            "4.0K\t./TensorRT-LLM/3rdparty/NVTX\n",
            "4.0K\t./TensorRT-LLM/3rdparty/cxxopts\n",
            "4.0K\t./TensorRT-LLM/3rdparty/json\n",
            "4.0K\t./TensorRT-LLM/3rdparty/pybind11\n",
            "4.0K\t./TensorRT-LLM/3rdparty/xgrammar\n",
            "32K\t./TensorRT-LLM/3rdparty\n",
            "44K\t./TensorRT-LLM/docker/common\n",
            "68K\t./TensorRT-LLM/docker\n",
            "12K\t./TensorRT-LLM/windows/examples/llama\n",
            "16K\t./TensorRT-LLM/windows/examples\n",
            "20K\t./TensorRT-LLM/windows/docker\n",
            "64K\t./TensorRT-LLM/windows\n",
            "12K\t./TensorRT-LLM/docs/source/llm-api\n",
            "28K\t./TensorRT-LLM/docs/source/python-api\n",
            "76K\t./TensorRT-LLM/docs/source/architecture\n",
            "656K\t./TensorRT-LLM/docs/source/blogs/media\n",
            "696K\t./TensorRT-LLM/docs/source/blogs\n",
            "36K\t./TensorRT-LLM/docs/source/installation\n",
            "8.0K\t./TensorRT-LLM/docs/source/_templates\n",
            "20K\t./TensorRT-LLM/docs/source/llm-api-examples\n",
            "64K\t./TensorRT-LLM/docs/source/media\n",
            "132K\t./TensorRT-LLM/docs/source/advanced\n",
            "72K\t./TensorRT-LLM/docs/source/performance\n",
            "12K\t./TensorRT-LLM/docs/source/commands\n",
            "56K\t./TensorRT-LLM/docs/source/reference\n",
            "1.3M\t./TensorRT-LLM/docs/source\n",
            "1.4M\t./TensorRT-LLM/docs\n",
            "40K\t./TensorRT-LLM/tensorrt_llm/bench/build\n",
            "20K\t./TensorRT-LLM/tensorrt_llm/bench/utils\n",
            "32K\t./TensorRT-LLM/tensorrt_llm/bench/benchmark/utils\n",
            "56K\t./TensorRT-LLM/tensorrt_llm/bench/benchmark\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/bench/dataclasses\n",
            "172K\t./TensorRT-LLM/tensorrt_llm/bench\n",
            "180K\t./TensorRT-LLM/tensorrt_llm/llmapi\n",
            "264K\t./TensorRT-LLM/tensorrt_llm/quantization\n",
            "48K\t./TensorRT-LLM/tensorrt_llm/tools/plugin_gen/templates\n",
            "104K\t./TensorRT-LLM/tensorrt_llm/tools/plugin_gen\n",
            "172K\t./TensorRT-LLM/tensorrt_llm/tools\n",
            "36K\t./TensorRT-LLM/tensorrt_llm/plugin\n",
            "28K\t./TensorRT-LLM/tensorrt_llm/models/unet/pp\n",
            "112K\t./TensorRT-LLM/tensorrt_llm/models/unet\n",
            "48K\t./TensorRT-LLM/tensorrt_llm/models/deepseek_v2\n",
            "64K\t./TensorRT-LLM/tensorrt_llm/models/eagle\n",
            "36K\t./TensorRT-LLM/tensorrt_llm/models/recurrentgemma\n",
            "20K\t./TensorRT-LLM/tensorrt_llm/models/commandr\n",
            "108K\t./TensorRT-LLM/tensorrt_llm/models/qwen\n",
            "152K\t./TensorRT-LLM/tensorrt_llm/models/llama\n",
            "64K\t./TensorRT-LLM/tensorrt_llm/models/baichuan\n",
            "104K\t./TensorRT-LLM/tensorrt_llm/models/gpt\n",
            "20K\t./TensorRT-LLM/tensorrt_llm/models/dbrx\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/bloom\n",
            "64K\t./TensorRT-LLM/tensorrt_llm/models/chatglm\n",
            "68K\t./TensorRT-LLM/tensorrt_llm/models/redrafter\n",
            "28K\t./TensorRT-LLM/tensorrt_llm/models/gptj\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/opt\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/models/phi3\n",
            "100K\t./TensorRT-LLM/tensorrt_llm/models/enc_dec\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/models/falcon\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/models/bert\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/mpt\n",
            "28K\t./TensorRT-LLM/tensorrt_llm/models/phi\n",
            "44K\t./TensorRT-LLM/tensorrt_llm/models/deepseek_v1\n",
            "76K\t./TensorRT-LLM/tensorrt_llm/models/nemotron_nas\n",
            "44K\t./TensorRT-LLM/tensorrt_llm/models/grok\n",
            "36K\t./TensorRT-LLM/tensorrt_llm/models/cogvlm\n",
            "56K\t./TensorRT-LLM/tensorrt_llm/models/medusa\n",
            "24K\t./TensorRT-LLM/tensorrt_llm/models/dit\n",
            "84K\t./TensorRT-LLM/tensorrt_llm/models/mllama\n",
            "40K\t./TensorRT-LLM/tensorrt_llm/models/gemma/utils\n",
            "164K\t./TensorRT-LLM/tensorrt_llm/models/gemma\n",
            "56K\t./TensorRT-LLM/tensorrt_llm/models/mamba\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/models/gptneox\n",
            "2.0M\t./TensorRT-LLM/tensorrt_llm/models\n",
            "16K\t./TensorRT-LLM/tensorrt_llm/runtime/memory_pools\n",
            "512K\t./TensorRT-LLM/tensorrt_llm/runtime\n",
            "52K\t./TensorRT-LLM/tensorrt_llm/commands\n",
            "40K\t./TensorRT-LLM/tensorrt_llm/auto_parallel/tensor_parallel/plugin_nodes\n",
            "268K\t./TensorRT-LLM/tensorrt_llm/auto_parallel/tensor_parallel\n",
            "596K\t./TensorRT-LLM/tensorrt_llm/auto_parallel\n",
            "272K\t./TensorRT-LLM/tensorrt_llm/layers\n",
            "48K\t./TensorRT-LLM/tensorrt_llm/serve\n",
            "4.9M\t./TensorRT-LLM/tensorrt_llm\n",
            "116K\t./TensorRT-LLM/tests/bindings\n",
            "32K\t./TensorRT-LLM/tests/llmapi/_perf_evaluator\n",
            "48K\t./TensorRT-LLM/tests/llmapi/apps\n",
            "240K\t./TensorRT-LLM/tests/llmapi\n",
            "180K\t./TensorRT-LLM/tests/quantization\n",
            "16K\t./TensorRT-LLM/tests/python_plugin\n",
            "20K\t./TensorRT-LLM/tests/tools/plugin_gen\n",
            "24K\t./TensorRT-LLM/tests/tools\n",
            "32K\t./TensorRT-LLM/tests/model_api\n",
            "44K\t./TensorRT-LLM/tests/utils\n",
            "232K\t./TensorRT-LLM/tests/attention\n",
            "440K\t./TensorRT-LLM/tests/functional\n",
            "204K\t./TensorRT-LLM/tests/model/eagle\n",
            "96K\t./TensorRT-LLM/tests/model/redrafter\n",
            "604K\t./TensorRT-LLM/tests/model\n",
            "2.2M\t./TensorRT-LLM/tests\n",
            "20K\t./TensorRT-LLM/cpp/cmake/modules\n",
            "8.0K\t./TensorRT-LLM/cpp/cmake/utils\n",
            "8.0K\t./TensorRT-LLM/cpp/cmake/templates\n",
            "40K\t./TensorRT-LLM/cpp/cmake\n",
            "19M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager/aarch64-linux-gnu\n",
            "48M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager/x86_64-windows-msvc\n",
            "15M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager/x86_64-linux-gnu\n",
            "81M\t./TensorRT-LLM/cpp/tensorrt_llm/batch_manager\n",
            "5.3M\t./TensorRT-LLM/cpp/tensorrt_llm/executor/aarch64-linux-gnu\n",
            "25M\t./TensorRT-LLM/cpp/tensorrt_llm/executor/x86_64-windows-msvc\n",
            "7.2M\t./TensorRT-LLM/cpp/tensorrt_llm/executor/x86_64-linux-gnu\n",
            "37M\t./TensorRT-LLM/cpp/tensorrt_llm/executor\n",
            "12K\t./TensorRT-LLM/cpp/tensorrt_llm/executor_worker\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lowLatencyGemmSwigluPlugin\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/quantizeTensorPlugin\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/loraPlugin\n",
            "44K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/weightOnlyGroupwiseQuantMatmulPlugin\n",
            "172K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gptAttentionCommon\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/qserveGemmPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/cumsumLastDimPlugin\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gemmSwigluPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/topkLastDimPlugin\n",
            "132K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/eaglePlugin\n",
            "28K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/quantizePerTokenPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/mambaConv1dPlugin\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/rmsnormQuantizationPlugin\n",
            "76K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/mixtureOfExperts\n",
            "36K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/weightOnlyQuantMatmulPlugin\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/api\n",
            "28K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/cudaStreamPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lowLatencyGemmPlugin\n",
            "96K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/ncclPlugin\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/selectiveScanPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lookupPlugin\n",
            "84K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/common\n",
            "48K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/bertAttentionPlugin\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/identityPlugin\n",
            "28K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/cpSplitPlugin\n",
            "92K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gptAttentionPlugin\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/gemmPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/fp8RowwiseGemmPlugin\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/layernormQuantizationPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/lruPlugin\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/plugins/smoothQuantGemmPlugin\n",
            "1.5M\t./TensorRT-LLM/cpp/tensorrt_llm/plugins\n",
            "16K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/transform/threadblock\n",
            "20K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/transform\n",
            "8.0K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue/thread\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue/collective\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue/threadblock\n",
            "76K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/epilogue\n",
            "292K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/kernel\n",
            "48K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/warp\n",
            "32K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/collective/builders\n",
            "196K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/collective\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/device\n",
            "208K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm/threadblock\n",
            "788K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/gemm\n",
            "12K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/util\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions/arch\n",
            "972K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include/cutlass_extensions\n",
            "976K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions/include\n",
            "980K\t./TensorRT-LLM/cpp/tensorrt_llm/cutlass_extensions\n",
            "292K\t./TensorRT-LLM/cpp/tensorrt_llm/common\n",
            "60K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/selectiveScan/instantiation\n",
            "344K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/selectiveScan\n",
            "79M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/aarch64-linux-gnu\n",
            "1.1M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/x86_64-windows-msvc\n",
            "81M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/x86_64-linux-gnu\n",
            "8.0K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper/include\n",
            "161M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT/nvrtcWrapper\n",
            "161M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/decoderXQAImplJIT\n",
            "232K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/instantiation\n",
            "118M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention/cubin\n",
            "279M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/decoderMaskedMultiheadAttention\n",
            "156K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/weightOnlyBatchedGemv\n",
            "156K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/mixtureOfExperts\n",
            "712M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/contextFusedMultiHeadAttention/cubin\n",
            "712M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/contextFusedMultiHeadAttention\n",
            "37M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/aarch64-linux-gnu\n",
            "2.6M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/x86_64-windows-msvc\n",
            "62M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/x86_64-linux-gnu\n",
            "16K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels/include\n",
            "101M\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/internal_cutlass_kernels\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/lora\n",
            "116K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/unfusedAttentionKernels\n",
            "68K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fp8_rowwise_gemm\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/moe_gemm/launchers\n",
            "160K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/moe_gemm\n",
            "40K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fused_gated_gemm\n",
            "44K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/int8_gemm\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fpA_intB_gemm/launchers\n",
            "152K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/fpA_intB_gemm\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels/python\n",
            "568K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/cutlass_kernels\n",
            "304K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/speculativeDecoding\n",
            "148K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/userbuffers\n",
            "76K\t./TensorRT-LLM/cpp/tensorrt_llm/kernels/beamSearchKernels\n",
            "1.1G\t./TensorRT-LLM/cpp/tensorrt_llm/kernels\n",
            "184K\t./TensorRT-LLM/cpp/tensorrt_llm/thop\n",
            "60K\t./TensorRT-LLM/cpp/tensorrt_llm/runtime/utils\n",
            "784K\t./TensorRT-LLM/cpp/tensorrt_llm/runtime\n",
            "112K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/batch_manager\n",
            "116K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/executor\n",
            "16K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/common\n",
            "24K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind/runtime\n",
            "308K\t./TensorRT-LLM/cpp/tensorrt_llm/pybind\n",
            "408K\t./TensorRT-LLM/cpp/tensorrt_llm/layers\n",
            "1.2G\t./TensorRT-LLM/cpp/tensorrt_llm\n",
            "280K\t./TensorRT-LLM/cpp/include/tensorrt_llm/batch_manager\n",
            "152K\t./TensorRT-LLM/cpp/include/tensorrt_llm/executor\n",
            "8.0K\t./TensorRT-LLM/cpp/include/tensorrt_llm/plugins/api\n",
            "12K\t./TensorRT-LLM/cpp/include/tensorrt_llm/plugins\n",
            "108K\t./TensorRT-LLM/cpp/include/tensorrt_llm/common\n",
            "12K\t./TensorRT-LLM/cpp/include/tensorrt_llm/kernels\n",
            "16K\t./TensorRT-LLM/cpp/include/tensorrt_llm/runtime/utils\n",
            "344K\t./TensorRT-LLM/cpp/include/tensorrt_llm/runtime\n",
            "8.0K\t./TensorRT-LLM/cpp/include/tensorrt_llm/layers\n",
            "920K\t./TensorRT-LLM/cpp/include/tensorrt_llm\n",
            "924K\t./TensorRT-LLM/cpp/include\n",
            "28K\t./TensorRT-LLM/cpp/tests/utils\n",
            "60K\t./TensorRT-LLM/cpp/tests/common\n",
            "16K\t./TensorRT-LLM/cpp/tests/kernels/smoothQuant\n",
            "140K\t./TensorRT-LLM/cpp/tests/kernels/sampling\n",
            "48K\t./TensorRT-LLM/cpp/tests/kernels/fused_gated_gemm\n",
            "20K\t./TensorRT-LLM/cpp/tests/kernels/cudaCoreGemm\n",
            "24K\t./TensorRT-LLM/cpp/tests/kernels/weightOnly\n",
            "20K\t./TensorRT-LLM/cpp/tests/kernels/allReduce\n",
            "568K\t./TensorRT-LLM/cpp/tests/kernels\n",
            "8.0K\t./TensorRT-LLM/cpp/tests/thop\n",
            "344K\t./TensorRT-LLM/cpp/tests/runtime\n",
            "484K\t./TensorRT-LLM/cpp/tests/layers\n",
            "224K\t./TensorRT-LLM/cpp/tests/resources/scripts\n",
            "44K\t./TensorRT-LLM/cpp/tests/resources/data\n",
            "32K\t./TensorRT-LLM/cpp/tests/resources/models\n",
            "308K\t./TensorRT-LLM/cpp/tests/resources\n",
            "1.8M\t./TensorRT-LLM/cpp/tests\n",
            "76K\t./TensorRT-LLM/cpp/micro_benchmarks\n",
            "1.2G\t./TensorRT-LLM/cpp\n",
            "4.0K\t./TensorRT-LLM/.git/objects/info\n",
            "463M\t./TensorRT-LLM/.git/objects/pack\n",
            "463M\t./TensorRT-LLM/.git/objects\n",
            "8.0K\t./TensorRT-LLM/.git/logs/refs/remotes/origin\n",
            "12K\t./TensorRT-LLM/.git/logs/refs/remotes\n",
            "16K\t./TensorRT-LLM/.git/logs/refs\n",
            "24K\t./TensorRT-LLM/.git/logs\n",
            "8.0K\t./TensorRT-LLM/.git/info\n",
            "4.0K\t./TensorRT-LLM/.git/branches\n",
            "80K\t./TensorRT-LLM/.git/hooks\n",
            "8.0K\t./TensorRT-LLM/.git/refs/remotes/origin\n",
            "12K\t./TensorRT-LLM/.git/refs/remotes\n",
            "4.0K\t./TensorRT-LLM/.git/refs/tags\n",
            "4.0K\t./TensorRT-LLM/.git/refs/heads\n",
            "24K\t./TensorRT-LLM/.git/refs\n",
            "48M\t./TensorRT-LLM/.git/lfs/objects/64/76\n",
            "48M\t./TensorRT-LLM/.git/lfs/objects/64\n",
            "2.6M\t./TensorRT-LLM/.git/lfs/objects/e5/23\n",
            "2.6M\t./TensorRT-LLM/.git/lfs/objects/e5\n",
            "3.7M\t./TensorRT-LLM/.git/lfs/objects/2f/a6\n",
            "3.7M\t./TensorRT-LLM/.git/lfs/objects/2f\n",
            "24K\t./TensorRT-LLM/.git/lfs/objects/ed/a1\n",
            "28K\t./TensorRT-LLM/.git/lfs/objects/ed\n",
            "3.6M\t./TensorRT-LLM/.git/lfs/objects/5a/8a\n",
            "3.6M\t./TensorRT-LLM/.git/lfs/objects/5a\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/a6/e7\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/a6\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/95/c9\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/95\n",
            "7.4M\t./TensorRT-LLM/.git/lfs/objects/c5/23\n",
            "7.4M\t./TensorRT-LLM/.git/lfs/objects/c5\n",
            "81M\t./TensorRT-LLM/.git/lfs/objects/2d/f5\n",
            "81M\t./TensorRT-LLM/.git/lfs/objects/2d\n",
            "7.5M\t./TensorRT-LLM/.git/lfs/objects/50/cc\n",
            "7.5M\t./TensorRT-LLM/.git/lfs/objects/50\n",
            "1.9M\t./TensorRT-LLM/.git/lfs/objects/86/d1\n",
            "1.9M\t./TensorRT-LLM/.git/lfs/objects/86\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/79/45\n",
            "2.7M\t./TensorRT-LLM/.git/lfs/objects/79\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/ae/74\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/ae\n",
            "25M\t./TensorRT-LLM/.git/lfs/objects/af/7b\n",
            "25M\t./TensorRT-LLM/.git/lfs/objects/af\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/0c/c7\n",
            "19M\t./TensorRT-LLM/.git/lfs/objects/0c\n",
            "31M\t./TensorRT-LLM/.git/lfs/objects/db/6c\n",
            "31M\t./TensorRT-LLM/.git/lfs/objects/db\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/e4/d5\n",
            "8.2M\t./TensorRT-LLM/.git/lfs/objects/e4\n",
            "32M\t./TensorRT-LLM/.git/lfs/objects/b6/1c\n",
            "32M\t./TensorRT-LLM/.git/lfs/objects/b6\n",
            "79M\t./TensorRT-LLM/.git/lfs/objects/53/9c\n",
            "79M\t./TensorRT-LLM/.git/lfs/objects/53\n",
            "8.0K\t./TensorRT-LLM/.git/lfs/objects/02/bd\n",
            "12K\t./TensorRT-LLM/.git/lfs/objects/02\n",
            "1.1M\t./TensorRT-LLM/.git/lfs/objects/62/d0\n",
            "1.1M\t./TensorRT-LLM/.git/lfs/objects/62\n",
            "379M\t./TensorRT-LLM/.git/lfs/objects\n",
            "4.0K\t./TensorRT-LLM/.git/lfs/incomplete\n",
            "4.0K\t./TensorRT-LLM/.git/lfs/tmp\n",
            "379M\t./TensorRT-LLM/.git/lfs\n",
            "842M\t./TensorRT-LLM/.git\n",
            "2.1G\t./TensorRT-LLM\n",
            "26G\t./vicuna_model\n",
            "55M\t./sample_data\n",
            "28G\t.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !python3 TensorRT-LLM/examples/llama/convert_checkpoint.py --model_dir ./vicuna_model/ --output_dir ./TensorRT-LLM/tllm_checkpoint_1gpu_fp16/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Puv1XBL53RF",
        "outputId": "bba95f7d-18aa-4826-d33a-27bedcd33d1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TensorRT-LLM] TensorRT-LLM version: 0.16.0\n",
            "0.16.0\n",
            "[01/30/2025-06:24:28] [TRT-LLM] [I] Specified dtype 'auto'; inferred dtype 'float16'.\n",
            "[01/30/2025-06:24:28] [TRT-LLM] [W] Implicitly setting LLaMAConfig.tie_word_embeddings = False\n",
            "192it [01:52,  1.23it/s]^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls TensorRT-LLM/tllm_checkpoint_1gpu_fp16"
      ],
      "metadata": {
        "id": "mbu893lbytou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -c \"from llama_index.llms.nvidia_tensorrt import LocalTensorRTLLM; llm = LocalTensorRTLLM(model_path='./engine_outputs', engine_name='gpt_float16_tp1_rank0.engine', tokenizer_dir='gpt2', max_new_tokens=40)\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYzJa-69GVwf",
        "outputId": "edf48b60-1a5b-4ec7-975c-bb6268a2b210",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[TensorRT-LLM] TensorRT-LLM version: 0.16.0\n",
            "Traceback (most recent call last):\n",
            "  File \"<string>\", line 1, in <module>\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/llama_index/llms/nvidia_tensorrt/base.py\", line 170, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: Provided model path does not exist. Please check the path or provide a model_url to download.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HXsgFsqVYEPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9nsFaPq1Gr9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7O_6FruVLjH"
      },
      "source": [
        "# Nvidia TensorRT-LLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm5B73q7VLjJ"
      },
      "source": [
        "\n",
        "TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs.\n",
        "\n",
        "[TensorRT-LLM Github](https://github.com/NVIDIA/TensorRT-LLM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DLMD6thVLjL"
      },
      "source": [
        "## TensorRT-LLM Environment Setup\n",
        "Since TensorRT-LLM is a SDK for interacting with local models in process there are a few environment steps that must be followed to ensure that the TensorRT-LLM setup can be used. Please note, that Nvidia Cuda 12.2 or higher is currently required to run TensorRT-LLM.\n",
        "\n",
        "In this tutorial we will show how to use the connector with GPT2 model.\n",
        "For the best experience, we recommend following\n",
        "[Installation](https://github.com/NVIDIA/TensorRT-LLM/tree/v0.8.0?tab=readme-ov-file#installation) process on the\n",
        "official [TensorRT-LLM Github](https://github.com/NVIDIA/TensorRT-LLM).\n",
        "\n",
        "The following steps are showing how to set up your model with TensorRT-LLM v0.8.0 for x86_64 users.\n",
        "\n",
        "1. Obtain and start the basic docker image environment.\n",
        "```\n",
        "docker run --rm --runtime=nvidia --gpus all --entrypoint /bin/bash -it nvidia/cuda:12.1.0-devel-ubuntu22.04\n",
        "```\n",
        "\n",
        "2. Install dependencies, TensorRT-LLM requires Python 3.10\n",
        "```\n",
        "apt-get update && apt-get -y install python3.10 python3-pip openmpi-bin libopenmpi-dev git git-lfs wget\n",
        "```\n",
        "3. Install the latest stable version (corresponding to the release branch) of TensorRT-LLM. We are using version 0.8.0, but for the most up to date release,\n",
        "please refer to [official release page](https://github.com/NVIDIA/TensorRT-LLM/releases).\n",
        "```\n",
        "pip3 install tensorrt_llm==0.8.0 -U --extra-index-url https://pypi.nvidia.com\n",
        "```\n",
        "\n",
        "4. Check installation\n",
        "```\n",
        "python3 -c \"import tensorrt_llm\"\n",
        "```\n",
        "The above command should not produce any errors.\n",
        "\n",
        "5. For this example we will use GPT2. The GPT2 model files need to be created via scripts following the instructions [here](https://github.com/NVIDIA/TensorRT-LLM/tree/main/examples/gpt#usage)\n",
        "    * First, inside the container, we've started during stage 1, clone TensorRT-LLM repository:\n",
        "    ```\n",
        "    git clone --branch v0.8.0 https://github.com/NVIDIA/TensorRT-LLM.git\n",
        "    ```\n",
        "    * Install requirements for GPT2 model with:\n",
        "    ```\n",
        "    cd TensorRT-LLM/examples/gpt/ && pip install -r requirements.txt\n",
        "    ```\n",
        "    * Download hf gpt2 model\n",
        "    ```\n",
        "    rm -rf gpt2 && git clone https://huggingface.co/gpt2-medium gpt2\n",
        "    cd gpt2\n",
        "    rm pytorch_model.bin model.safetensors\n",
        "    wget -q https://huggingface.co/gpt2-medium/resolve/main/pytorch_model.bin\n",
        "    cd ..\n",
        "    ```\n",
        "    * Convert weights from HF Transformers to TensorRT-LLM format\n",
        "    ```\n",
        "    python3 hf_gpt_convert.py -i gpt2 -o ./c-model/gpt2 --tensor-parallelism 1 --storage-type float16\n",
        "    ```\n",
        "    * Build TensorRT engine\n",
        "    ```\n",
        "    python3 build.py --model_dir=./c-model/gpt2/1-gpu --use_gpt_attention_plugin --remove_input_padding\n",
        "    ```\n",
        "  \n",
        "6. Install `llama-index-llms-nvidia-tensorrt` package\n",
        "  ```\n",
        "  pip install llama-index-llms-nvidia-tensorrt\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!ls /content/drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9y_dgPpHlQV",
        "outputId": "9fc06dbc-4274-479e-d5ed-e4e368bdb592"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCQy3sMdVLjN"
      },
      "source": [
        "## Basic Usage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iXZhnF7VLjP"
      },
      "source": [
        "#### Call `complete` with a prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO4IGYjMVLjP"
      },
      "source": [
        "```python\n",
        "from llama_index.llms.nvidia_tensorrt import LocalTensorRTLLM\n",
        "\n",
        "llm = LocalTensorRTLLM(\n",
        "    model_path=\"./engine_outputs\",\n",
        "    engine_name=\"gpt_float16_tp1_rank0.engine\",\n",
        "    tokenizer_dir=\"gpt2\",\n",
        "    max_new_tokens=40,\n",
        ")\n",
        "\n",
        "resp = llm.complete(\"Who is Harry Potter?\")\n",
        "print(str(resp))\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKjc8VRqVLjR"
      },
      "source": [
        "The expected response should look like:\n",
        "```\n",
        "Harry Potter is a fictional character created by J.K. Rowling in her first novel, Harry Potter and the Philosopher's Stone. The character is a wizard who lives in the fictional town#\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XFAOnzFVVORc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3"
    },
    "vscode": {
      "interpreter": {
        "hash": "a0a0263b650d907a3bfe41c0f8d6a63a071b884df3cfdc1579f00cdc1aed6b03"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}